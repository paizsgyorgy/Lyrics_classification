{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get one song: George Ezra - Budapest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get('https://www.lyrics.com/lyric/18961542/Queen/The+Show+Must+Go+On+%5B%2A%5D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = soup(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_text = page.find_all(attrs={'class':'lyric-body'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_text[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all songs and lyrics from Queen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download the website that contains all songs of the artist\n",
    "html = requests.get('https://www.lyrics.com/artist/Queen/5205')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parse the HTML site with BeautifulSoup\n",
    "urls_page = soup(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract all tags with 'a' from the parsed through html file\n",
    "a = urls_page.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the attribute out of an href for one tag 'a' (example) - this gives us the URL for a specific song\n",
    "a[70].get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get all the URLs for Queen songs on Lyrics.com\n",
    "urls = []\n",
    "for i in a:\n",
    "    if '/lyric/' in i.get('href'):\n",
    "        urls.append(i.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get all the titles for Queen songs on Lyrics.com\n",
    "titles = []\n",
    "for i in a:\n",
    "    if '/lyric/' in i.get('href'):\n",
    "        titles.append(i.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:29<00:00,  3.34s/it]\n"
     ]
    }
   ],
   "source": [
    "## Create empty list for lyrics to be filled in\n",
    "lyrics = []\n",
    "\n",
    "## Put the lyrics in a list\n",
    "for i in tqdm(urls):\n",
    "    url = 'https://www.lyrics.com' + i\n",
    "    html = requests.get(url)\n",
    "    page = soup(html.text, 'html.parser')\n",
    "    try:\n",
    "        refined_text = page.find_all(attrs={'class':'lyric-body'})\n",
    "        lyrics.append(refined_text[0].text)\n",
    "    except:\n",
    "        lyrics.append(np.NaN)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put all three lists into a dataframe\n",
    "df = pd.DataFrame({'URL':['https://www.lyrics.com' + i for i in urls],'Title':titles, 'Lyrics': lyrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write dataframe to a csv file\n",
    "df.to_csv('Queen_lyrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function that takes a URL of an artist discography and outputs a dataframe with lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics(url):\n",
    "    \"\"\"\n",
    "    This function takes a URL from a selected artist on Lyrics.com and outputs a dataframe including all its songs lyrics\n",
    "    \"\"\"\n",
    "    ## Download website under url\n",
    "    html = requests.get(url)\n",
    "    \n",
    "    ## Parse the HTML site with BeautifulSoup\n",
    "    urls_page = soup(html.text, 'html.parser')\n",
    "    \n",
    "    ## Extract all tags with 'a' from the parsed through html file\n",
    "    a = urls_page.find_all('a')\n",
    "    \n",
    "    ## Get all the URLs and titles for the artists' songs on Lyrics.com\n",
    "    urls = []\n",
    "    titles = []\n",
    "    for i in a:\n",
    "        if '/lyric/' in i.get('href'):\n",
    "            urls.append(i.get('href'))\n",
    "            titles.append(i.get_text())\n",
    "            \n",
    "    ## Download all the lyrics for all the songs listed from the artist\n",
    "    lyrics = []\n",
    "    \n",
    "    for i in urls:\n",
    "        url = 'https://www.lyrics.com' + i\n",
    "        try:\n",
    "            html = requests.get(url)\n",
    "            page = soup(html.text, 'html.parser')\n",
    "            try:\n",
    "                refined_text = page.find_all(attrs={'class':'lyric-body'})\n",
    "                lyrics.append(refined_text[0].text)\n",
    "            except:\n",
    "                lyrics.append(np.NaN)\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(1)\n",
    "        \n",
    "    ## Create a dataframe out of the three lists\n",
    "    \n",
    "    df = pd.DataFrame({'URL':['https://www.lyrics.com' + i for i in urls],'Title':titles, 'Lyrics': lyrics})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get lyrics for The Rolling Stones\n",
    "df_rolling = get_lyrics('https://www.lyrics.com/artist/The+Rolling+Stones/5298')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write dataframe to a csv file\n",
    "df_rolling.to_csv('RollingStones_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get lyrics for The Rolling Stones\n",
    "df_miley = get_lyrics('https://www.lyrics.com/artist/Miley+Cyrus/823418')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write dataframe to a csv file\n",
    "df_miley.to_csv('Output/MileyCyrus_lyrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a small program to search for any name and get back the lyrics of that artist from Lyrics.com\n",
    "\n",
    "This will only work with the (maximum) 6 top options that Lyrics returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load necessary packages for the program to run\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initiate user search and prompt user for input\n",
    "user_search = input('What do you want to search for?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Strip user input and replace user input whitespaces with '%20' that is used as space on Lyrics.com\n",
    "user_search = user_search.strip()\n",
    "user_search = re.sub('( ){1,}', '%20', user_search)\n",
    "user_search = user_search.lower()\n",
    "\n",
    "### Create link to be used for going to search results site on Lyrics.com\n",
    "searchlink = 'https://www.lyrics.com/lyrics/' + user_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parse the website with beautifulsoup\n",
    "html = requests.get(searchlink)\n",
    "searchpage = soup(html.text, 'html.parser')\n",
    "\n",
    "a = searchpage.find_all('a')\n",
    "\n",
    "artist_urls = []\n",
    "artist_names = []\n",
    "\n",
    "for i in a:\n",
    "    if 'artist/' in i.get('href'):\n",
    "        artist_urls.append('https://www.lyrics.com/' + i.get('href'))\n",
    "        artist_names.append(i.get('title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create options dataframe (there are duplicates and we want to select only the first nine occurances)\n",
    "artist_opts = pd.DataFrame({'URL':artist_urls[0:18:2],'Name':artist_names[0:18:2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print out each element in my artist_names list for the user to choose from\n",
    "print('The following artists were found on Lyrics.com for your search:')\n",
    "for i, name in enumerate(artist_opts['Name']):\n",
    "    print(str(i+1) + ') ' + str(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompt user for input and confirm the input of the user is among the listed options\n",
    "while True:\n",
    "    try:\n",
    "        user_selection = input('Please type the number of the artist you want to load lyrics from: ')\n",
    "        if int(user_selection) in list((artist_opts.index.values + 1)):\n",
    "            break\n",
    "        else:\n",
    "            raise ValueError\n",
    "    except ValueError:\n",
    "        print(\"Not a valid option! Please try again ...\")\n",
    "\n",
    "## Print an empty line and then the user selected artist name\n",
    "print()\n",
    "print(f'Great, I will search lyrics for: {artist_opts.iloc[int(user_selection)-1, 1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save selected artist url in artist_url variable\n",
    "artist_url = artist_opts.iloc[int(user_selection)-1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run the user defined function that scrapes the website for lyrics and puts it into a dataframe\n",
    "lyrics = get_lyrics(artist_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = artist_opts.iloc[int(user_selection)-1, 1]\n",
    "artist_shortened = ''.join(e for e in string if e.isalnum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write out dataframe to a csv output file\n",
    "filename = f'{artist_shortened}_lyrics.csv'\n",
    "lyrics.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all this into one lyrics downloader program\n",
    "--> This program is saved as LyricsSearch.py to be run directly from the Terminal (try running it with your favorite singer!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What do you want to search for? Gotye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following artists were found on Lyrics.com for your search:\n",
      "1) Gotye\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please type the number of the artist you want to load lyrics from:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Great, I will search lyrics for: Gotye\n",
      "\n",
      "It will take approximately 1 minutes 18 seconds to load all 26 songs from this artist.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to continue? (Y/N) Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [01:30<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All lyrics loaded into dataframe.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c57d3473e09d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mlyrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mdirpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "### Load necessary packages for the program to run\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "### Create user defined function for scraping lyrics\n",
    "def get_lyrics(urls):\n",
    "    \"\"\"\n",
    "    This function takes a urls from an artist on Lyrics.com and outputs a dataframe including all its songs lyrics\n",
    "    \"\"\"\n",
    " \n",
    "    ## Download all the lyrics for all the songs listed from the artist\n",
    "    lyrics = []\n",
    "\n",
    "    ## For loop including a tqdm progress bar (super cool!)\n",
    "    for i in tqdm(urls):\n",
    "        url = 'https://www.lyrics.com' + i\n",
    "        try:\n",
    "            html = requests.get(url)\n",
    "            page = soup(html.text, 'html.parser')\n",
    "            try:\n",
    "                refined_text = page.find_all(attrs={'class':'lyric-body'})\n",
    "                lyrics.append(refined_text[0].text)\n",
    "            except:\n",
    "                lyrics.append(np.NaN)\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(1)\n",
    "\n",
    "    ## Create a dataframe out of the three lists\n",
    "\n",
    "    df = pd.DataFrame({'URL':['https://www.lyrics.com' + i for i in urls],'Title':titles, 'Lyrics': lyrics})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "### Initiate user search and prompt user for input\n",
    "user_search = input('What do you want to search for?')\n",
    "\n",
    "### Strip user input and replace user input whitespaces with '%20' that is used as space on Lyrics.com\n",
    "user_search = user_search.strip()\n",
    "user_search = re.sub('( ){1,}', '%20', user_search)\n",
    "user_search = user_search.lower()\n",
    "\n",
    "### Create link to be used for going to search results site on Lyrics.com\n",
    "searchlink = 'https://www.lyrics.com/lyrics/' + user_search\n",
    "\n",
    "### Parse the website with beautifulsoup\n",
    "html = requests.get(searchlink)\n",
    "searchpage = soup(html.text, 'html.parser')\n",
    "\n",
    "a = searchpage.find_all('a')\n",
    "\n",
    "artist_urls = []\n",
    "artist_names = []\n",
    "\n",
    "for i in a:\n",
    "    if 'artist/' in i.get('href'):\n",
    "        artist_urls.append('https://www.lyrics.com/' + i.get('href'))\n",
    "        artist_names.append(i.get('title'))\n",
    "\n",
    "## Create options dataframe (there are duplicates and we want to select only the first nine occurances)\n",
    "artist_opts = pd.DataFrame({'URL':artist_urls[0:18:2],'Name':artist_names[0:18:2]})\n",
    "\n",
    "## Print out each element in my artist_names list for the user to choose from\n",
    "print()\n",
    "print('The following artists were found on Lyrics.com for your search:')\n",
    "for i, name in enumerate(artist_opts['Name']):\n",
    "    print(str(i+1) + ') ' + str(name))\n",
    "\n",
    "print()\n",
    "\n",
    "## Prompt user for input and confirm the input of the user is among the listed options\n",
    "while True:\n",
    "    try:\n",
    "        user_selection = input('Please type the number of the artist you want to load lyrics from: ')\n",
    "        if int(user_selection) in list((artist_opts.index.values + 1)):\n",
    "            break\n",
    "        else:\n",
    "            raise ValueError\n",
    "    except ValueError:\n",
    "        print(\"Not a valid option! Please try again ...\")\n",
    "        \n",
    "### Print an empty line and then the user selected artist name\n",
    "print()\n",
    "print(f'Great, I will search lyrics for {artist_opts.iloc[int(user_selection)-1, 1]}')\n",
    "\n",
    "### Save selected artist url in artist_url variable\n",
    "artist_url = artist_opts.iloc[int(user_selection)-1, 0]\n",
    "\n",
    "## Download artist website under url\n",
    "html = requests.get(artist_url)\n",
    "\n",
    "## Parse the HTML site with BeautifulSoup\n",
    "urls_page = soup(html.text, 'html.parser')\n",
    "\n",
    "## Extract all tags with 'a' from the parsed through html file\n",
    "a = urls_page.find_all('a')\n",
    "\n",
    "## Get all the URLs and titles for the artists' songs on Lyrics.com\n",
    "urls = []\n",
    "titles = []\n",
    "for i in a:\n",
    "    if '/lyric/' in i.get('href'):\n",
    "        urls.append(i.get('href'))\n",
    "        titles.append(i.get_text())\n",
    "\n",
    "### Estimate time it will take to load all lyrics and confirm with user\n",
    "est = len(urls) * 3\n",
    "est_min = est // 60\n",
    "est_sec = est % 60\n",
    "print()\n",
    "print(f'It will take approximately {est_min} minutes {est_sec} seconds to load all {len(urls)} songs from this artist.')\n",
    "print()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        confirm = input('Do you want to continue? (Y/N)')\n",
    "        if confirm in ['Y','N']:\n",
    "            break\n",
    "        else:\n",
    "            raise ValueError\n",
    "    except ValueError:\n",
    "        print(\"Not a valid option! Please try again with Y or N...\")\n",
    "\n",
    "if confirm == 'N':\n",
    "    print('Okay then, quitting the program...')\n",
    "    quit()\n",
    "\n",
    "else:  \n",
    "    ### Run the user defined function that scrapes the website for lyrics and puts it into a dataframe\n",
    "    ### A tqdm progress bar is included in the defined function above\n",
    "    lyrics = get_lyrics(urls)\n",
    "\n",
    "    ### Print message\n",
    "    print()\n",
    "    print('All lyrics loaded into dataframe.')\n",
    "\n",
    "    ### Strip down the artist name to be used for filename\n",
    "    string = artist_opts.iloc[int(user_selection)-1, 1]\n",
    "    artist_shortened = ''.join(e for e in string if e.isalnum())\n",
    "\n",
    "    ### Write out dataframe to a csv output file\n",
    "    filename = f'{artist_shortened}_lyrics.csv'\n",
    "    lyrics.to_csv(filename)\n",
    "\n",
    "    dirpath = os.getcwd()\n",
    "    filepath = dirpath + '/' + filename\n",
    "\n",
    "    ### Print message\n",
    "    print()\n",
    "    print(f'CSV file created with all lyrics for artist {string}.')\n",
    "    print(f'The file is saved in the following location:  {filepath}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
